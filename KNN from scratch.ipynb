{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7d5cfb",
   "metadata": {},
   "source": [
    "## Objective\n",
    "IMPLEMENT K-NN from Scratch !\n",
    "\n",
    "The test problem we will be using in this tutorial is the iris classification.\n",
    "\n",
    "The problem is comprised of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length, and petal width, all in the same unit of centimeters. The predicted attribute is the species, which is one of Setosa, Versicolor, or Virginica.\n",
    "\n",
    "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct, typically 96% or better.\n",
    "\n",
    "Save the file in your current working directory with the file name “iris.data“.\n",
    "\n",
    "This tutorial is broken down into the following steps:\n",
    "\n",
    "Handle Data: Open the dataset from CSV and split it into test/train datasets.\n",
    "\n",
    "Similarity: Calculate the distance between two data instances.\n",
    "\n",
    "Neighbors: Locate k most similar data instances.\n",
    "\n",
    "Response: Generate a response from a set of data instances.\n",
    "\n",
    "Accuracy: Summarize the accuracy of predictions.\n",
    "\n",
    "Main: Tie it all together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003e4a5",
   "metadata": {},
   "source": [
    "## 1. Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b06ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1, 3.5, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.0, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.3, 0.2, Iris-setosa\n",
      "4.6, 3.1, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.6, 1.4, 0.2, Iris-setosa\n",
      "5.4, 3.9, 1.7, 0.4, Iris-setosa\n",
      "4.6, 3.4, 1.4, 0.3, Iris-setosa\n",
      "5.0, 3.4, 1.5, 0.2, Iris-setosa\n",
      "4.4, 2.9, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.4, 3.7, 1.5, 0.2, Iris-setosa\n",
      "4.8, 3.4, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.1, Iris-setosa\n",
      "4.3, 3.0, 1.1, 0.1, Iris-setosa\n",
      "5.8, 4.0, 1.2, 0.2, Iris-setosa\n",
      "5.7, 4.4, 1.5, 0.4, Iris-setosa\n",
      "5.4, 3.9, 1.3, 0.4, Iris-setosa\n",
      "5.1, 3.5, 1.4, 0.3, Iris-setosa\n",
      "5.7, 3.8, 1.7, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.5, 0.3, Iris-setosa\n",
      "5.4, 3.4, 1.7, 0.2, Iris-setosa\n",
      "5.1, 3.7, 1.5, 0.4, Iris-setosa\n",
      "4.6, 3.6, 1.0, 0.2, Iris-setosa\n",
      "5.1, 3.3, 1.7, 0.5, Iris-setosa\n",
      "4.8, 3.4, 1.9, 0.2, Iris-setosa\n",
      "5.0, 3.0, 1.6, 0.2, Iris-setosa\n",
      "5.0, 3.4, 1.6, 0.4, Iris-setosa\n",
      "5.2, 3.5, 1.5, 0.2, Iris-setosa\n",
      "5.2, 3.4, 1.4, 0.2, Iris-setosa\n",
      "4.7, 3.2, 1.6, 0.2, Iris-setosa\n",
      "4.8, 3.1, 1.6, 0.2, Iris-setosa\n",
      "5.4, 3.4, 1.5, 0.4, Iris-setosa\n",
      "5.2, 4.1, 1.5, 0.1, Iris-setosa\n",
      "5.5, 4.2, 1.4, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "5.0, 3.2, 1.2, 0.2, Iris-setosa\n",
      "5.5, 3.5, 1.3, 0.2, Iris-setosa\n",
      "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
      "4.4, 3.0, 1.3, 0.2, Iris-setosa\n",
      "5.1, 3.4, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.3, 0.3, Iris-setosa\n",
      "4.5, 2.3, 1.3, 0.3, Iris-setosa\n",
      "4.4, 3.2, 1.3, 0.2, Iris-setosa\n",
      "5.0, 3.5, 1.6, 0.6, Iris-setosa\n",
      "5.1, 3.8, 1.9, 0.4, Iris-setosa\n",
      "4.8, 3.0, 1.4, 0.3, Iris-setosa\n",
      "5.1, 3.8, 1.6, 0.2, Iris-setosa\n",
      "4.6, 3.2, 1.4, 0.2, Iris-setosa\n",
      "5.3, 3.7, 1.5, 0.2, Iris-setosa\n",
      "5.0, 3.3, 1.4, 0.2, Iris-setosa\n",
      "7.0, 3.2, 4.7, 1.4, Iris-versicolor\n",
      "6.4, 3.2, 4.5, 1.5, Iris-versicolor\n",
      "6.9, 3.1, 4.9, 1.5, Iris-versicolor\n",
      "5.5, 2.3, 4.0, 1.3, Iris-versicolor\n",
      "6.5, 2.8, 4.6, 1.5, Iris-versicolor\n",
      "5.7, 2.8, 4.5, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 4.7, 1.6, Iris-versicolor\n",
      "4.9, 2.4, 3.3, 1.0, Iris-versicolor\n",
      "6.6, 2.9, 4.6, 1.3, Iris-versicolor\n",
      "5.2, 2.7, 3.9, 1.4, Iris-versicolor\n",
      "5.0, 2.0, 3.5, 1.0, Iris-versicolor\n",
      "5.9, 3.0, 4.2, 1.5, Iris-versicolor\n",
      "6.0, 2.2, 4.0, 1.0, Iris-versicolor\n",
      "6.1, 2.9, 4.7, 1.4, Iris-versicolor\n",
      "5.6, 2.9, 3.6, 1.3, Iris-versicolor\n",
      "6.7, 3.1, 4.4, 1.4, Iris-versicolor\n",
      "5.6, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "5.8, 2.7, 4.1, 1.0, Iris-versicolor\n",
      "6.2, 2.2, 4.5, 1.5, Iris-versicolor\n",
      "5.6, 2.5, 3.9, 1.1, Iris-versicolor\n",
      "5.9, 3.2, 4.8, 1.8, Iris-versicolor\n",
      "6.1, 2.8, 4.0, 1.3, Iris-versicolor\n",
      "6.3, 2.5, 4.9, 1.5, Iris-versicolor\n",
      "6.1, 2.8, 4.7, 1.2, Iris-versicolor\n",
      "6.4, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "6.6, 3.0, 4.4, 1.4, Iris-versicolor\n",
      "6.8, 2.8, 4.8, 1.4, Iris-versicolor\n",
      "6.7, 3.0, 5.0, 1.7, Iris-versicolor\n",
      "6.0, 2.9, 4.5, 1.5, Iris-versicolor\n",
      "5.7, 2.6, 3.5, 1.0, Iris-versicolor\n",
      "5.5, 2.4, 3.8, 1.1, Iris-versicolor\n",
      "5.5, 2.4, 3.7, 1.0, Iris-versicolor\n",
      "5.8, 2.7, 3.9, 1.2, Iris-versicolor\n",
      "6.0, 2.7, 5.1, 1.6, Iris-versicolor\n",
      "5.4, 3.0, 4.5, 1.5, Iris-versicolor\n",
      "6.0, 3.4, 4.5, 1.6, Iris-versicolor\n",
      "6.7, 3.1, 4.7, 1.5, Iris-versicolor\n",
      "6.3, 2.3, 4.4, 1.3, Iris-versicolor\n",
      "5.6, 3.0, 4.1, 1.3, Iris-versicolor\n",
      "5.5, 2.5, 4.0, 1.3, Iris-versicolor\n",
      "5.5, 2.6, 4.4, 1.2, Iris-versicolor\n",
      "6.1, 3.0, 4.6, 1.4, Iris-versicolor\n",
      "5.8, 2.6, 4.0, 1.2, Iris-versicolor\n",
      "5.0, 2.3, 3.3, 1.0, Iris-versicolor\n",
      "5.6, 2.7, 4.2, 1.3, Iris-versicolor\n",
      "5.7, 3.0, 4.2, 1.2, Iris-versicolor\n",
      "5.7, 2.9, 4.2, 1.3, Iris-versicolor\n",
      "6.2, 2.9, 4.3, 1.3, Iris-versicolor\n",
      "5.1, 2.5, 3.0, 1.1, Iris-versicolor\n",
      "5.7, 2.8, 4.1, 1.3, Iris-versicolor\n",
      "6.3, 3.3, 6.0, 2.5, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "7.1, 3.0, 5.9, 2.1, Iris-virginica\n",
      "6.3, 2.9, 5.6, 1.8, Iris-virginica\n",
      "6.5, 3.0, 5.8, 2.2, Iris-virginica\n",
      "7.6, 3.0, 6.6, 2.1, Iris-virginica\n",
      "4.9, 2.5, 4.5, 1.7, Iris-virginica\n",
      "7.3, 2.9, 6.3, 1.8, Iris-virginica\n",
      "6.7, 2.5, 5.8, 1.8, Iris-virginica\n",
      "7.2, 3.6, 6.1, 2.5, Iris-virginica\n",
      "6.5, 3.2, 5.1, 2.0, Iris-virginica\n",
      "6.4, 2.7, 5.3, 1.9, Iris-virginica\n",
      "6.8, 3.0, 5.5, 2.1, Iris-virginica\n",
      "5.7, 2.5, 5.0, 2.0, Iris-virginica\n",
      "5.8, 2.8, 5.1, 2.4, Iris-virginica\n",
      "6.4, 3.2, 5.3, 2.3, Iris-virginica\n",
      "6.5, 3.0, 5.5, 1.8, Iris-virginica\n",
      "7.7, 3.8, 6.7, 2.2, Iris-virginica\n",
      "7.7, 2.6, 6.9, 2.3, Iris-virginica\n",
      "6.0, 2.2, 5.0, 1.5, Iris-virginica\n",
      "6.9, 3.2, 5.7, 2.3, Iris-virginica\n",
      "5.6, 2.8, 4.9, 2.0, Iris-virginica\n",
      "7.7, 2.8, 6.7, 2.0, Iris-virginica\n",
      "6.3, 2.7, 4.9, 1.8, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.1, Iris-virginica\n",
      "7.2, 3.2, 6.0, 1.8, Iris-virginica\n",
      "6.2, 2.8, 4.8, 1.8, Iris-virginica\n",
      "6.1, 3.0, 4.9, 1.8, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.1, Iris-virginica\n",
      "7.2, 3.0, 5.8, 1.6, Iris-virginica\n",
      "7.4, 2.8, 6.1, 1.9, Iris-virginica\n",
      "7.9, 3.8, 6.4, 2.0, Iris-virginica\n",
      "6.4, 2.8, 5.6, 2.2, Iris-virginica\n",
      "6.3, 2.8, 5.1, 1.5, Iris-virginica\n",
      "6.1, 2.6, 5.6, 1.4, Iris-virginica\n",
      "7.7, 3.0, 6.1, 2.3, Iris-virginica\n",
      "6.3, 3.4, 5.6, 2.4, Iris-virginica\n",
      "6.4, 3.1, 5.5, 1.8, Iris-virginica\n",
      "6.0, 3.0, 4.8, 1.8, Iris-virginica\n",
      "6.9, 3.1, 5.4, 2.1, Iris-virginica\n",
      "6.7, 3.1, 5.6, 2.4, Iris-virginica\n",
      "6.9, 3.1, 5.1, 2.3, Iris-virginica\n",
      "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
      "6.8, 3.2, 5.9, 2.3, Iris-virginica\n",
      "6.7, 3.3, 5.7, 2.5, Iris-virginica\n",
      "6.7, 3.0, 5.2, 2.3, Iris-virginica\n",
      "6.3, 2.5, 5.0, 1.9, Iris-virginica\n",
      "6.5, 3.0, 5.2, 2.0, Iris-virginica\n",
      "6.2, 3.4, 5.4, 2.3, Iris-virginica\n",
      "5.9, 3.0, 5.1, 1.8, Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "#The first thing we need to do is load our data file. \n",
    "import csv\n",
    "\n",
    "with open('downloads/iris.data.txt', 'r') as csvfile:\n",
    "    lines = csv.reader(csvfile)\n",
    "    for row in lines :\n",
    "        print (', '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54c5854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we need to split the data into a training dataset \n",
    "import random\n",
    "import csv\n",
    "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        random.seed(0)\n",
    "        random.shuffle(dataset)\n",
    "        for x in range(len(dataset)):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "        indx= int(len(dataset)*split)\n",
    "        trainingSet= dataset[:indx]\n",
    "        testSet=dataset[indx:]\n",
    "\n",
    "        return trainingSet , testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99ad63ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#We can test this function out with our iris dataset, as follows:\n",
    "\n",
    "trainingSet=[]\n",
    "testSet = []\n",
    "\n",
    "loadDataset('downloads/iris.data.txt', 0.66,trainingSet , testSet)\n",
    "\n",
    "print(len(trainingSet),len(testSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25a556",
   "metadata": {},
   "source": [
    "## 2. Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227a7e4",
   "metadata": {},
   "source": [
    "To make predictions we need to calculate the similarity between any two given data instances. This is needed so that we can locate the k most similar data instances in the training dataset for a given member of the test dataset and in turn, make a prediction.\n",
    "\n",
    "Given that all four flower measurements are numeric and have the same units, we can directly use the Euclidean distance measure. \n",
    "\n",
    "Additionally, we want to control which fields to include in the distance calculation. Specifically, we only want to include the first 4 attributes. One approach is to limit the Euclidean distance to a fixed length, ignoring the final dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7da3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the euclidean distance\n",
    "import math\n",
    "def euclideanDistance(instance1, instance2, length):\n",
    "    difference_squared = 0\n",
    "    for x in range(length):\n",
    "        difference_squared += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(difference_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62982e",
   "metadata": {},
   "source": [
    "## 3. Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d43086",
   "metadata": {},
   "source": [
    "Now that we have a similarity measure, we can use it to collect the k most similar instances for a given unseen instance.\n",
    "\n",
    "This is a straightforward process of calculating the distance for all instances and selecting a subset with the smallest distance values.\n",
    "\n",
    "Below is the getNeighbors function that returns k most similar neighbors from the training set for a given test instance (using the already defined euclideanDistance function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31a07a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k,distance_metric=None):\n",
    "   \n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    #print(length)\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = distance_metric(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "      \n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "        #print('distances sorted',distances)\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "        #print('The new one look like neighbors', neighbors)\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d1331",
   "metadata": {},
   "source": [
    "## 4. Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f071b",
   "metadata": {},
   "source": [
    "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on those neighbors.\n",
    "\n",
    "We can do this by allowing each neighbor to vote for their class attribute, and take the majority vote as the prediction.\n",
    "\n",
    "Below provides a function for getting the majority voted response from a number of neighbors. It assumes the class is the last attribute for each neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd1173cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1] #complete with appropriate number\n",
    "        \n",
    "        classVotes.setdefault(response,0)\n",
    "        if response in classVotes.keys():\n",
    "            # increase frequency by +1\n",
    "            classVotes[response] +=1\n",
    "\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c99ff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "#We can test out this function with some test neighbors, as follows:\n",
    "\n",
    "neighbors = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
    "response = getResponse(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036be20",
   "metadata": {},
   "source": [
    "This approach returns one response in the case of a draw, but you could handle such cases in a specific way, such as returning no response or selecting an unbiased random response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d9616",
   "metadata": {},
   "source": [
    "## 5. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e2db7",
   "metadata": {},
   "source": [
    "We have all of the pieces of the kNN algorithm in place. An important remaining concern is how to evaluate the accuracy of predictions.\n",
    "\n",
    "An easy way to evaluate the accuracy of the model is to calculate a ratio of the total correct predictions out of all predictions made, called the classification accuracy.\n",
    "\n",
    "Below is the getAccuracy function that sums the total correct predictions and returns the accuracy as a percentage of correct classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac8dfebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    # Complete the function\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct +=1\n",
    "   \n",
    "    return (correct/len(testSet)) * 100.0\n",
    "\n",
    "# We can test this function with a test dataset and predictions, as follows:\n",
    "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b85aa",
   "metadata": {},
   "source": [
    "## 6. Main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6612498b",
   "metadata": {},
   "source": [
    "We now have all the elements of the algorithm, we can put them all in one main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04e80337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_filename, k, split, distanceFunc):\n",
    "    \n",
    "    trainingSet, testSet=loadDataset(dataset_filename, split)\n",
    "    \n",
    "    predictions = []\n",
    "    for testInstance in testSet:\n",
    "        neighbors = getNeighbors(trainingSet, testInstance[:-1], k, distanceFunc)\n",
    "        response = getResponse(neighbors)\n",
    "        predictions.append(response)\n",
    "        \n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print(\"Accuracy = %.2f\" % accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11c3f",
   "metadata": {},
   "source": [
    "## 7. Another distance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587b141",
   "metadata": {},
   "source": [
    "define another distance metric instead of euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d6698e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattanDistance(instance1, instance2, length):\n",
    "    #   Complete the function\n",
    "    distance = 0\n",
    "    for i in range(length):\n",
    "        distance += abs(instance2[i]-instance1[i])\n",
    "\n",
    "    return distance\n",
    "\n",
    "def minkowskiDistance(instance1, instance2, length,degree=2):\n",
    "    difference_squared = 0\n",
    "    for x in range(length):\n",
    "        difference_squared += pow((instance1[x] - instance2[x]), degree)\n",
    "    return pow(difference_squared,1/degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9fd3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.16\n",
      "Accuracy = 92.16\n",
      "Accuracy = 92.16\n",
      "Accuracy = 92.16\n",
      "Accuracy = 92.16\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 92.16\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 94.12\n",
      "Accuracy = 92.16\n",
      "Accuracy = 92.16\n",
      "Accuracy = 94.12\n",
      "Accuracy = 92.16\n",
      "Accuracy = 94.12\n",
      "Accuracy = 96.08\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "for k in range(1,31):\n",
    "    accuracy=main(\"downloads/iris.data.txt\", k, 0.66, manhattanDistance)\n",
    "    scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95760a",
   "metadata": {},
   "source": [
    "### The best accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74f4600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best Accuracy is 96.07843137254902\n",
      "best k is : 30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"the best Accuracy is\",np.max(scores))\n",
    "print(\"best k is :\", np.argmax(scores)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285f666",
   "metadata": {},
   "source": [
    "### Plot to confirm it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24099756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23c61c6e070>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,31),scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
